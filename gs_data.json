{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "sp5VwJoAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Cong Guo", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=sp5VwJoAAAAJ&citpid=25", "affiliation": "Duke University", "organization": 7484523900994334132, "interests": ["Computer architecture", "High performance computing"], "email_domain": "@duke.edu", "homepage": "https://clevercool.github.io/", "citedby": 1169, "publications": {"sp5VwJoAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Olive: Accelerating large language models via hardware-friendly outlier-victim pair quantization", "pub_year": "2023"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:WF5omc3nYNoC", "num_citations": 201, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12793780007815349245", "cites_id": ["12793780007815349245"]}, "sp5VwJoAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dual-side sparse tensor core", "pub_year": "2021"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:qjMakFHDy7sC", "num_citations": 158, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1947360210180954922,9109547410965471957", "cites_id": ["1947360210180954922", "9109547410965471957"]}, "sp5VwJoAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Accelerating sparse dnn models without hardware-support via tile-wise sparsity", "pub_year": "2020"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:2osOgNQ5qMEC", "num_citations": 125, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7286352271358395852", "cites_id": ["7286352271358395852"]}, "sp5VwJoAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ant: Exploiting adaptive numerical data type for low-bit deep neural network quantization", "pub_year": "2022"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:Y0pCki6q_DkC", "num_citations": 115, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2012579182738653117", "cites_id": ["2012579182738653117"]}, "sp5VwJoAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Squant: On-the-fly data-free quantization via diagonal hessian approximation", "pub_year": "2022"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:IjCSPb-OGe4C", "num_citations": 101, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=748228209807839980", "cites_id": ["748228209807839980"]}, "sp5VwJoAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Characterizing and demystifying the implicit convolution algorithm on commercial matrix-multiplication accelerators", "pub_year": "2021"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:UeHWp8X0CEIC", "num_citations": 71, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2805360911536211547", "cites_id": ["2805360911536211547"]}, "sp5VwJoAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adversarial defense through network profiling based path extraction", "pub_year": "2019"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:u-x6o8ySG0sC", "num_citations": 70, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1524434831389854833", "cites_id": ["1524434831389854833"]}, "sp5VwJoAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Gmlake: Efficient and transparent gpu memory defragmentation for large-scale dnn training with virtual memory stitching", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:LkGwnXOMwfcC", "num_citations": 41, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11607622023292858749", "cites_id": ["11607622023292858749"]}, "sp5VwJoAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Balancing efficiency and flexibility for DNN acceleration via temporal GPU-systolic array integration", "pub_year": "2020"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:d1gkVwhDpl0C", "num_citations": 40, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5807191488226178448", "cites_id": ["5807191488226178448"]}, "sp5VwJoAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Juno: Optimizing high-dimensional approximate nearest neighbour search with sparsity-aware algorithm and ray-tracing core mapping", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:_FxGoFyzp5QC", "num_citations": 33, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14118762042279685435", "cites_id": ["14118762042279685435"]}, "sp5VwJoAAAAJ:HDshCWvjkbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A survey: Collaborative hardware and software design in the era of large language models", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:HDshCWvjkbEC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8067128018050350101", "cites_id": ["8067128018050350101"]}, "sp5VwJoAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M-ANT: Efficient low-bit group quantization for LLMs via mathematically adaptive numerical type", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:TQgYirikUcIC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12386392630302487874", "cites_id": ["12386392630302487874"]}, "sp5VwJoAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Accelerating sparse dnns based on tiled gemm", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:roLk4NBRz8UC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6933468290879164170", "cites_id": ["6933468290879164170"]}, "sp5VwJoAAAAJ:R3hNpaxXUhUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vq-llm: High-performance code generation for vector quantization augmented llm inference", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:R3hNpaxXUhUC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=751903200703059906", "cites_id": ["751903200703059906"]}, "sp5VwJoAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "vtensor: Flexible virtual tensor management for efficient llm serving", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:hqOjcs7Dif8C", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4167428666596350941", "cites_id": ["4167428666596350941"]}, "sp5VwJoAAAAJ:bEWYMUwI8FkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dpad: Efficient diffusion language models with suffix dropout", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:bEWYMUwI8FkC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1700655227555170689", "cites_id": ["1700655227555170689"]}, "sp5VwJoAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DSTC: Dual-Side Sparse Tensor Core for DNNs Acceleration on Modern GPU Architectures", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:5nxA0vEk-isC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16927198548843525929", "cites_id": ["16927198548843525929"]}, "sp5VwJoAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Efficient adaptive activation rounding for post-training quantization", "pub_year": "2022"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:Tyk-4Ss8FVUC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8527761287947401664", "cites_id": ["8527761287947401664"]}, "sp5VwJoAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ecco: Improving memory bandwidth and capacity for llms via entropy-aware cache compression", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:RHpTSmoSYBkC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10610644994543063052", "cites_id": ["10610644994543063052"]}, "sp5VwJoAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Nesting forward automatic differentiation for memory-efficient deep neural network training", "pub_year": "2022"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:W7OEmFMy1HYC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7546643443996096642", "cites_id": ["7546643443996096642"]}, "sp5VwJoAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Transitive array: An efficient gemm accelerator with result reuse", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:_Qo2XoVZTnwC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12301897127889678777", "cites_id": ["12301897127889678777"]}, "sp5VwJoAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prosperity: Accelerating spiking neural networks via product sparsity", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:e5wmG9Sq2KIC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2034504683167629977", "cites_id": ["2034504683167629977"]}, "sp5VwJoAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Neuromorphic computing in the era of large models", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:4JMBOYKVnBMC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16142757913205843690", "cites_id": ["16142757913205843690"]}, "sp5VwJoAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaptgear: Accelerating gnn training via adaptive subgraph-level kernels on gpus", "pub_year": "2023"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:ufrVoPGSRksC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11593628498629948439", "cites_id": ["11593628498629948439"]}, "sp5VwJoAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards reliable AI applications via algorithm-based fault tolerance on NVDLA", "pub_year": "2022"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:eQOLeE2rZwMC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14466500169402882237", "cites_id": ["14466500169402882237"]}, "sp5VwJoAAAAJ:M3NEmzRMIkIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ellm: Elastic memory management framework for efficient llm serving", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:M3NEmzRMIkIC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8946783732519297391", "cites_id": ["8946783732519297391"]}, "sp5VwJoAAAAJ:r0BpntZqJG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Phi: Leveraging pattern-based hierarchical sparsity for high-efficiency spiking neural networks", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:r0BpntZqJG4C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4549710030973722621", "cites_id": ["4549710030973722621"]}, "sp5VwJoAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Accelerating generic graph neural networks via architecture, compiler, partition method co-design", "pub_year": "2023"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:MXK_kJrjxJIC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5325669178832100720", "cites_id": ["5325669178832100720"]}, "sp5VwJoAAAAJ:JV2RwH3_ST0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Sample-Free Compilation Framework for Efficient Dynamic Tensor Computation", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:JV2RwH3_ST0C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9679280222655598477", "cites_id": ["9679280222655598477"]}, "sp5VwJoAAAAJ:blknAaTinKkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Focus: A Streaming Concentration Architecture for Efficient Vision-Language Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:blknAaTinKkC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3145529908071102040", "cites_id": ["3145529908071102040"]}, "sp5VwJoAAAAJ:TFP_iSt0sucC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Circuits to systems: co-designing efficient AI hardware", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:TFP_iSt0sucC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16333625227607700703", "cites_id": ["16333625227607700703"]}, "sp5VwJoAAAAJ:k_IJM867U9cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Accurate and Efficient 3D Object Detection for Autonomous Driving: A Mixture of Experts Computing System on Edge", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:k_IJM867U9cC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17136583316951579485", "cites_id": ["17136583316951579485"]}, "sp5VwJoAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vortex: Efficient Sample-Free Dynamic Tensor Program Optimization via Hardware-aware Strategy Space Hierarchization", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:8k81kl-MbHgC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17585159193069141581", "cites_id": ["17585159193069141581"]}, "sp5VwJoAAAAJ:NMxIlDl6LWMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Platinum: Path-Adaptable LUT-Based Accelerator Tailored for Low-Bit Weight Matrix Multiplication", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:NMxIlDl6LWMC", "num_citations": 0}, "sp5VwJoAAAAJ:YFjsv_pBGBYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CAMformer: Associative Memory is All You Need", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:YFjsv_pBGBYC", "num_citations": 0}, "sp5VwJoAAAAJ:hMod-77fHWUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FractalCloud: A Fractal-Inspired Architecture for Efficient Large-Scale Point Cloud Processing", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:hMod-77fHWUC", "num_citations": 0}, "sp5VwJoAAAAJ:maZDTaKrznsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Full-Stack Framework for GNN Acceleration via Partition-Compiler-Architecture Co-Design", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:maZDTaKrznsC", "num_citations": 0}}, "citedby5y": 1148, "hindex": 15, "hindex5y": 15, "i10index": 20, "i10index5y": 19, "cites_per_year": {"2020": 18, "2021": 41, "2022": 89, "2023": 149, "2024": 263, "2025": 557, "2026": 48}, "updated": "2026-03-01 08:02:51.772772"}