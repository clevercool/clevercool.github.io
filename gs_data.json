{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "sp5VwJoAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Cong Guo", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=sp5VwJoAAAAJ&citpid=16", "affiliation": "Duke University", "organization": 7484523900994334132, "interests": ["Computer architecture", "High performance computing"], "email_domain": "@duke.edu", "homepage": "https://clevercool.github.io/", "citedby": 757, "publications": {"sp5VwJoAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dual-side sparse tensor core", "pub_year": "2021"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:qjMakFHDy7sC", "num_citations": 118, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1947360210180954922,9109547410965471957", "cites_id": ["1947360210180954922", "9109547410965471957"]}, "sp5VwJoAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Olive: Accelerating large language models via hardware-friendly outlier-victim pair quantization", "pub_year": "2023"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:WF5omc3nYNoC", "num_citations": 117, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12793780007815349245", "cites_id": ["12793780007815349245"]}, "sp5VwJoAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Accelerating sparse dnn models without hardware-support via tile-wise sparsity", "pub_year": "2020"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:2osOgNQ5qMEC", "num_citations": 109, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7286352271358395852", "cites_id": ["7286352271358395852"]}, "sp5VwJoAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Squant: On-the-fly data-free quantization via diagonal hessian approximation", "pub_year": "2022"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:IjCSPb-OGe4C", "num_citations": 83, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=748228209807839980", "cites_id": ["748228209807839980"]}, "sp5VwJoAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ant: Exploiting adaptive numerical data type for low-bit deep neural network quantization", "pub_year": "2022"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:Y0pCki6q_DkC", "num_citations": 70, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2012579182738653117", "cites_id": ["2012579182738653117"]}, "sp5VwJoAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adversarial defense through network profiling based path extraction", "pub_year": "2019"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:u-x6o8ySG0sC", "num_citations": 65, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1524434831389854833", "cites_id": ["1524434831389854833"]}, "sp5VwJoAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Characterizing and demystifying the implicit convolution algorithm on commercial matrix-multiplication accelerators", "pub_year": "2021"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:UeHWp8X0CEIC", "num_citations": 52, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2805360911536211547", "cites_id": ["2805360911536211547"]}, "sp5VwJoAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Balancing efficiency and flexibility for DNN acceleration via temporal GPU-systolic array integration", "pub_year": "2020"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:d1gkVwhDpl0C", "num_citations": 34, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5807191488226178448", "cites_id": ["5807191488226178448"]}, "sp5VwJoAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Gmlake: Efficient and transparent gpu memory defragmentation for large-scale dnn training with virtual memory stitching", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:LkGwnXOMwfcC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11607622023292858749", "cites_id": ["11607622023292858749"]}, "sp5VwJoAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "JUNO: Optimizing high-dimensional approximate nearest neighbour search with sparsity-aware algorithm and ray-tracing core mapping", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:_FxGoFyzp5QC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14118762042279685435", "cites_id": ["14118762042279685435"]}, "sp5VwJoAAAAJ:HDshCWvjkbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Survey: Collaborative Hardware and Software Design in the Era of Large Language Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:HDshCWvjkbEC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8067128018050350101", "cites_id": ["8067128018050350101"]}, "sp5VwJoAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Accelerating sparse dnns based on tiled gemm", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:roLk4NBRz8UC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6933468290879164170", "cites_id": ["6933468290879164170"]}, "sp5VwJoAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Efficient Adaptive Activation Rounding for Post-Training Quantization", "pub_year": "2022"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:Tyk-4Ss8FVUC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8527761287947401664", "cites_id": ["8527761287947401664"]}, "sp5VwJoAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "vtensor: Flexible virtual tensor management for efficient llm serving", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:hqOjcs7Dif8C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4167428666596350941", "cites_id": ["4167428666596350941"]}, "sp5VwJoAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Nesting forward automatic differentiation for memory-efficient deep neural network training", "pub_year": "2022"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:W7OEmFMy1HYC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7546643443996096642", "cites_id": ["7546643443996096642"]}, "sp5VwJoAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DSTC: Dual-Side Sparsity Tensor Core for DNNs Acceleration on Modern GPU Architectures", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:5nxA0vEk-isC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=617943872274664051", "cites_id": ["617943872274664051"]}, "sp5VwJoAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prosperity: Accelerating Spiking Neural Networks via Product Sparsity", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:e5wmG9Sq2KIC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2034504683167629977", "cites_id": ["2034504683167629977"]}, "sp5VwJoAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M-ANT: Efficient Low-bit Group Quantization for LLMs via Mathematically Adaptive Numerical Type", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:TQgYirikUcIC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12386392630302487874", "cites_id": ["12386392630302487874"]}, "sp5VwJoAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Accelerating generic graph neural networks via architecture, compiler, partition method co-design", "pub_year": "2023"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:MXK_kJrjxJIC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5325669178832100720", "cites_id": ["5325669178832100720"]}, "sp5VwJoAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards reliable AI applications via algorithm-based fault tolerance on NVDLA", "pub_year": "2022"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:eQOLeE2rZwMC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14466500169402882237", "cites_id": ["14466500169402882237"]}, "sp5VwJoAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Transitive Array: An Efficient GEMM Accelerator with Result Reuse", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:_Qo2XoVZTnwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12301897127889678777", "cites_id": ["12301897127889678777"]}, "sp5VwJoAAAAJ:R3hNpaxXUhUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VQ-LLM: High-performance Code Generation for Vector Quantization Augmented LLM Inference", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:R3hNpaxXUhUC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=751903200703059906", "cites_id": ["751903200703059906"]}, "sp5VwJoAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AdaptGear: Accelerating GNN Training via Adaptive Subgraph-Level Kernels on GPUs", "pub_year": "2023"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:ufrVoPGSRksC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11593628498629948439", "cites_id": ["11593628498629948439"]}, "sp5VwJoAAAAJ:RHpTSmoSYBkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ecco: Improving Memory Bandwidth and Capacity for LLMs via Entropy-aware Cache Compression", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:RHpTSmoSYBkC", "num_citations": 0}, "sp5VwJoAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Neuromorphic Computing in the Era of Large Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:4JMBOYKVnBMC", "num_citations": 0}, "sp5VwJoAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vortex: Efficient Sample-Free Dynamic Tensor Program Optimization via Hardware-aware Strategy Space Hierarchization", "pub_year": "2024"}, "filled": false, "author_pub_id": "sp5VwJoAAAAJ:8k81kl-MbHgC", "num_citations": 0}}, "citedby5y": 755, "hindex": 12, "hindex5y": 12, "i10index": 13, "i10index5y": 13, "cites_per_year": {"2020": 20, "2021": 41, "2022": 87, "2023": 152, "2024": 253, "2025": 200}, "updated": "2025-05-23 08:01:52.371263"}